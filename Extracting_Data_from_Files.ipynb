{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi05q89W79H3cQ3oSw2RuS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshithaaa11/NLP-excelr/blob/main/Extracting_Data_from_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC4ZNJAFJPX6",
        "outputId": "ca7a85b3-7b0e-4fea-e8ed-3d58099afc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx"
      ],
      "metadata": {
        "id": "-o0APuNGJZae"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k8p3d0K8Ksvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc=open(\"/content/AD-8 final report 1.docx\",\"rb\")\n",
        "document=docx.Document(doc)"
      ],
      "metadata": {
        "id": "b4LyBcfyJ6ib"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docu=\"\"\n",
        "for para in document.paragraphs:\n",
        "  docu+=para.text\n",
        "print(docu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyq52BqwKQrc",
        "outputId": "34a31a9f-fbbc-4f5e-d933-e8705f03b768"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Black and White Image Colorization with Deep LearningA project report submitted in partial fulfillment of the requirements for the award of the degree ofBachelor of TechnologybyUnder the guidance ofT.RamyaAssistant ProfessorDEPARTMENT OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNINGMALLA REDDY UNIVERSITY(As per Telangana State Private Universities Act No.13 of 2020 and G.O.Ms.No.14, Higher Education (UE) Department) HYDERABAD – 500043TELANAGANA INDIA2023-24MALLA REDDY UNIVERSITY(As per Telangana State Private Universities Act No.13 of 2020 and G.O.Ms.No.14, Higher Education (UE) Department) HYDERABAD – 500043TELANAGANACertificateThis is to certify that this is the bonafide record of the application development entitled, “Black and White Image Colorization with Deep Learning” submitted by L.Akhil (2111CS020028), B. Tech III year II semester, Department of CSE (AI &ML) during the year 2023-2024. The results embodied in the report have not been submitted to any other university or institute for the award of any degree or diploma.External Examiner ACKNOWLEDGEMENT     An endeavor over a long period can be successful with the advice and support of many well-wishers. We take this opportunity to express our gratitude and appreciation to all of them. We first take the privilege to thank Dr.Thayyaba Khatoon, Head of the Department, Computer Science & Engineering(AI&ML), for her valuable support and guidance during the period of project implementation. We wish to express our sincere thanks and gratitude to our project guideProf. T.Ramya, Professor, Department of Computer Science and Engineering(AI&ML) for the simulating discussions, in analyzing problems associated with our project work and for guiding us throughout the project. Project meetings were highly informative. We express our warm and sincere thanks for the encouragement, untiring guidance and the confidence she had shown in us. We are immensely indebted for her valuable guidance throughout our project. We also thank all the staff members of AIML department for their valuable advices. We also thank supporting staff for providing resources as and when required.ABSTRACT     The project, \" Black and White Image Colorization with Deep Learning,\" focuses on developing an innovative solution to automatically add realistic and aesthetically pleasing colors to grayscale images. Employing state-of-the-art deep learning techniques, including convolutional neural networks (CNNs) and generative models, our approach aims to capture intricate details and nuances in the colorization process. The abstracted methodology involves extensive training on diverse image datasets, fine-tuning model parameters, and exploring advanced loss functions to achieve high-fidelity color representations. The project not only addresses the technical challenges of accurate colorization but also aims to enhance user interactivity by providing customizable features such as style transfer and color grading. By combining the power of deep learning and computer vision, this project contributes to the broader field of image processing, offering a versatile tool for both historical photo restoration and creative content generation. Through experimentation and optimization, we aim to achieve a robust and user-friendly system that pushes the boundaries of image colorization in the digital era.                       CONTENTS1.INTRODUCTIONProblem definition:Colorization of black and white images is a longstanding challenge in computer vision, requiring the development of advanced algorithms to automatically add realistic colors to grayscale images. While manual colorization methods exist, they are time-consuming and labor-intensive. Additionally, existing automated solutions often lack accuracy and fail to capture intricate details accurately. Therefore, the project aims to leverage deep learning techniques to develop a robust and efficient system for black and white image colorization. This system should accurately infer color information from grayscale inputs, producing visually appealing and contextually appropriate colorized images. Key objectives include achieving high-quality colorization results across diverse image genres and optimizing computational efficiency to enable real-time or near-real-time performance on standard hardware configurations.Objective of project:The primary objectives include training the model on diverse datasets to ensure robust performance across various image styles, enhancing colorization accuracy through advanced feature extraction and context-aware mapping, and validating results using qualitative and quantitative evaluation metrics. Additionally, the project aims to provide a user-friendly interface for easy deployment and utilization, while also exploring avenues for further refinement and optimization, including real-time performance. Ultimately, the project seeks to contribute to advancements in computer vision and image processing fields by providing a reliable and scalable solution for automating the colorization process, with potential applications in digital restoration, historical preservation, and multimedia content creation.Scope & Limitations:Scope:Data Dependency: The effectiveness of deep learning models heavily relies on the availability and quality of training data. Limited or biased datasets may lead to suboptimal performance and generalization issues.Computational Resources: Training deep neural networks for image colorization requires significant computational resources, including high-performance GPUs and substantial memory capacity. This can pose challenges for individuals or organizations with limited access to such resources.Domain Specificity: Models trained on specific datasets may struggle to generalize to images from different domains or time periods. Adapting the model to diverse styles and contexts could require additional training or fine-tuning on relevant dataLimitations:Artifact Generation: Deep learning models may produce artifacts or unrealistic colorizations, especially in regions with complex textures or ambiguous features. Mitigating such artifacts typically requires post-processing techniques or refinement strategies.Ethical Considerations: Colorization algorithms may inadvertently perpetuate biases present in training data, leading to unintended consequences such as reinforcing stereotypes or cultural misrepresentations. Careful consideration of ethical implications is essential throughout the development and deployment of such technologies.Literature Survey:The literature surrounding black and white image colorization encompasses a diverse range of methodologies, techniques, and applications. Early approaches often relied on handcrafted rules or segmentation-based algorithms to assign colors to grayscale regions.Several studies have explored various architectures, loss functions, and training strategies to improve colorization quality and efficiency. For instance, Zhang et al. (2016) introduced a deep learning-based approach using a CNN to directly predict chrominance values from grayscale inputs, achieving impressive results.Similarly, Iizuka et al. (2016) proposed a deep learning framework incorporating a global and local colorization network to enhance colorization performance. Furthermore, advancements in generative adversarial networks (GANs) have led to novel techniques for realistic and high-resolution colorization, as demonstrated by Isola et al. (2017) with their pix2pix model. Beyond technical innovations, research in this area has also explored the cultural and historical implications of colorization, addressing issues such as authenticity, preservation of cultural heritage, and ethical considerations surrounding the manipulation of historical imagery.2. ANALYSISProject Planning and Research:Define project objectives: Establish the primary goal of developing a black and white image colorization model using deep learning.Resource allocation: Allocate personnel, computational resources, and budget for data acquisition, model development, and testing.Task prioritization: Prioritize tasks based on dependencies and project objectives to ensure efficient progress.Identify techniques and architectures: Explore popular techniques, architectures, datasets, and evaluation metrics used in previous studies.Model selection: Evaluate different deep learning architectures such as CNNs, GANs, and autoencoders for image colorization, considering factors like model complexity and performance on similar tasks.2.2 Software requirement specification: 2.2.1 Software requirement: 1.google colab or jupyter notebook: Notebook is an interact computing environment that allows you to create and share documents containing live code equations, visualizations, and narrative text. it’s commonly used for prototyping and experimenting with deep learning models. 2. Python Compiler with all the required modules available: All the Code written to execute the solution is written in the python code where any basic system with compiler and required specifications fulfilled can run the code. 3.Integrated Development Environment (IDE): IDEs like Visual studio code provide features like code editing, debugging, and project management making them essential for deep learning development workflows.2.2.2 Hardware requirement: 1.Memory (RAM): Sufficient RAM is essential for loading large datasets into memory, especially during data preprocessing and model training. Deep learning models with large parameter counts also require significant memory during training. 2.Central Processing unit (CPU) and Graphical Processing unit (GPU): Modern multi-core CPUs are essential for general-purpose computing tasks in deep learning, such as data processing, model evaluation.GPUs are the most widely used for deep learning due to their excellent support for CNNs and deep learning frameworks like TensorFlow and PyTorch. 3. NVIDIA GPU: Deep learning models benefit significantly from GPU acceleration. An NVIDIA GPU with CUDA support is recommended for faster training. For basic experimentation: NVIDIA GeForce GTX 1060 or higher.For larger models and datasets: NVIDIA GeForce RTX 2070 or higher, or NVIDIA Quadro series.Model Selection and Architecture: Model: Convolutional Neural Networks (CNNs):CNNs are widely used for various image-related tasks due to their ability to automatically learn hierarchical representations of input images. In the context of image colorization, CNNs can be trained to map grayscale images to corresponding color images.Effective at capturing local and global spatial dependencies in images.Can be trained end-to-end for image colorization tasks.Architecture: Fig.2.3.13.DESIGN3.1 Introduction:      The E-R diagram for a plant disease prediction system would typically include image analyzer image enhancement, image segmentation, feature extraction, classifier and detection. The datasets contain the images classified according to their plant health in different folders and these folders are used accordingly to train the CNN. 3.2 ER Diagram:Fig.3.2.13.3 Dataset Descriptions:    For an image colorization project using deep learning, you would typically need two types of datasets: grayscale images and their corresponding colorized versions.Grayscale Images:\n",
            "Grayscale images serve as the input to the colorization model. These images lack color information and are typically represented in shades of gray.\n",
            "Format: JPEG, PNG, or any other common image format.\n",
            "Size: Variable, depending on the source and application.Sample images:3.4 Data Preprocessing Techniques: Image Resizing : Resize images to a consistent resolution to ensure uniformity across the dataset. This step helps reduce computational overhead during training and ensures compatibility with the model's input size requirements..Normalization : Normalize pixel values to a common scale, typically between 0 and 1 or -1 and 1. Normalization helps stabilize training by ensuring that input values are within a similar range, which can improve convergence and model performance.3.5 Methods & Algorithms:Methods:      The methods involve the several steps of projects such as data collection, data pre processing choosing the model to train and train and test split of the model where finally the algorithms will be integrated to help with the predictions.Algorithms:Convolutional Neural Networks (CNNs)Encoder-Decoder Architecture : Utilized for learning high-level feature representations from input grayscale images and generating corresponding colorized outputs.Activation Functions : Typically ReLU (Rectified Linear Unit) activation functions are used in intermediate layers to introduce non-linearity.Normalization Layers : Batch normalization or instance normalization layers are often applied to stabilize and accelerate the training process.Preprocessing Techniques:Normalization : Normalizing input grayscale images to a standard range (e.g., [0, 1]) before feeding them into the network.DEPLOYMENT AND RESULTS4.1 Introduction:     To implement the project, the code was written in Python using libraries such as NumPy, OpenCV (cv2), and TensorFlow. The dataset preprocessing involved resizing images and converting them to suitable formats using NumPy arrays. The core of the implementation relied on Convolutional Neural Network (CNN) training, testing, and validation procedures to achieve image colorization.  4.2 Source Code:import numpy as npimport argparseimport cv2import osDIR = os.path.dirname(os.path.realpath(__file__))MODEL_DIR = os.path.join(DIR, \"model\") PROTOTXT = os.path.join(MODEL_DIR, \"colorization_deploy_v2.prototxt\")POINTS = os.path.join(MODEL_DIR, \"pts_in_hull.npy\")MODEL = os.path.join(MODEL_DIR, \"colorization_release_v2.caffemodel\")ap = argparse.ArgumentParser()ap.add_argument(\"-i\", \"--image\", type=str, required=True,                help=\"path to input black and white image\")args = vars(ap.parse_args())print(\"Loading model...\")net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)pts = np.load(POINTS)class8 = net.getLayerId(\"class8_ab\")conv8 = net.getLayerId(\"conv8_313_rh\")pts = pts.transpose().reshape(2, 313, 1, 1)net.getLayer(class8).blobs = [pts.astype(\"float32\")]net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]image = cv2.imread(args[\"image\"])scaled = image.astype(\"float32\") / 255.0lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)resized = cv2.resize(lab, (224, 224))L = cv2.split(resized)[0]L -= 50print(\"Colorizing the image...\")net.setInput(cv2.dnn.blobFromImage(L))ab = net.forward()[0, :, :, :].transpose((1, 2, 0))ab = cv2.resize(ab, (image.shape[1], image.shape[0]))L = cv2.split(lab)[0]colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)colorized = np.clip(colorized, 0, 1)colorized = (255 * colorized).astype(\"uint8\")cv2.imshow(\"Original\", image)cv2.imshow(\"Colorized\", colorized)cv2.waitKey(0)4.3 Model implementation and training:4.4 Model evaluation metrics:import cv2import numpy as npfrom skimage.metrics import structural_similarity as ssim# Function to calculate PSNRdef psnr(image1, image2):    mse = np.mean((image1 - image2) ** 2)    if mse == 0:        return float('inf')    max_pixel = 255.0    psnr_value = 20 * np.log10(max_pixel / np.sqrt(mse))    return psnr_value# Load the ground truth colorized image and the predicted colorized imageground_truth_color_image = cv2.imread('ground_truth_color_image.jpg')predicted_color_image = cv2.imread('predicted_color_image.jpg')# Convert images to grayscaleground_truth_color_image_gray = cv2.cvtColor(ground_truth_color_image, cv2.COLOR_BGR2GRAY)predicted_color_image_gray = cv2.cvtColor(predicted_color_image, cv2.COLOR_BGR2GRAY)# Calculate MSEmse = np.mean((ground_truth_color_image_gray - predicted_color_image_gray) ** 2)# Calculate PSNRpsnr_value = psnr(ground_truth_color_image_gray, predicted_color_image_gray)# Calculate SSIMssim_index = ssim(ground_truth_color_image_gray, predicted_color_image_gray)print(\"Mean Squared Error (MSE):\", mse)print(\"Peak Signal-to-Noise Ratio (PSNR):\", psnr_value)print(\"Structural Similarity Index (SSIM):\", ssim_index) 4.5 Model Deployment : Testing and Validationimport cv2import numpy as npfrom skimage.metrics import mean_squared_error# Function to calculate Mean Squared Error (MSE) between two imagesdef calculate_mse(image1, image2):    return mean_squared_error(image1, image2)# Load black and white image and its corresponding ground truth colored imagebw_image = cv2.imread('black_white_image.jpg', cv2.IMREAD_GRAYSCALE)ground_truth_colored_image = cv2.imread('ground_truth_colored_image.jpg')4.6 Web GUI’s Development:import tkinter as tkfrom tkinter import filedialogfrom PIL import Image, ImageTkimport numpy as npimport cv2import osdef colorize_image(image_path):    # Load the model    net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)    pts = np.load(POINTS)    class8 = net.getLayerId(\"class8_ab\")    conv8 = net.getLayerId(\"conv8_313_rh\")    pts = pts.transpose().reshape(2, 313, 1, 1)    net.getLayer(class8).blobs = [pts.astype(\"float32\")]    net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]    image = cv2.imread(image_path)    scaled = image.astype(\"float32\") / 255.0    lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)    resized = cv2.resize(lab, (224, 224))    L = cv2.split(resized)[0]    L -= 50    net.setInput(cv2.dnn.blobFromImage(L))    ab = net.forward()[0, :, :, :].transpose((1, 2, 0))    ab = cv2.resize(ab, (image.shape[1], image.shape[0]))    L = cv2.split(lab)[0]    colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)    colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)    colorized = np.clip(colorized, 0, 1)    colorized = (255 * colorized).astype(\"uint8\")    return colorizedroot = tk.Tk()root.title(\"Black and White Image original_label = tk.Label(root, text=\"Original Image\")original_label.grid(row=0, column=0, padx=10, pady=10)colorized_label = tk.Label(root, text=\"Colorized Image\")colorized_label.grid(row=0, column=1, padx=10, pady=10)def browse_and_colorize():    image_path = filedialog.askopenfilename()    colorized_image = colorize_image(image_path)    original_image = Image.open(image_path)    original_image.thumbnail((300, 300))    original_photo = ImageTk.PhotoImage(original_image)    original_label.config(image=original_photo)    original_label.image = original_photo    colorized_photo = ImageTk.PhotoImage(Image.fromarray(colorized_image))    colorized_label.config(image=colorized_photo)    colorized_label.image = colorized_photocolorize_button = tk.Button(root, text=\"Select and Colorize\", bg=\"#2ecc71\", fg=\"white\", relief=tk.FLAT, command=browse_and_colorize)colorize_button.grid(row=1, column=0, columnspan=2, padx=10, pady=10, sticky=\"we\")root.mainloop()Fig.4.6.1 4.7 Results:1. select the black and white image to be colorized2. click “Colorize”Fig.4.7.15.CONCLUSION5.1 Project conclusion:In conclusion, the ability to colorize black and white images has significant applications in various fields, including photography restoration, historical image enhancement, and artistic expression. Through the utilization of deep learning models, particularly convolutional neural networks (CNNs), we've developed a colorization model capable of transforming grayscale images into vibrant, color-rich representations.\n",
            "\n",
            "However, the effectiveness of such models heavily relies on the quality and diversity of the training data. Additionally, continuous improvements in model architecture, optimization techniques, and dataset augmentation strategies are essential to enhance the colorization accuracy and generalization capabilities. While our colorization model demonstrates promising results, there is still room for refinement and optimization. Future work could focus on addressing challenges such as handling complex scenes, improving color consistency, and expanding the model's applicability to diverse image datasets.5.2 Future Scope:Enhanced Model Architectures: Continuously refine and optimize deep learning architectures specifically designed for colorization tasks. This includes exploring novel network architectures, such as attention mechanisms, recurrent neural networks (RNNs), or transformer models, to improve colorization accuracy and efficiency.\n",
            "Fine-grained Colorization: Develop techniques to enable more precise and detailed colorization, especially in regions with intricate patterns or textures. This could involve integrating high-resolution image representations or leveraging advanced feature extraction methods.Interactive Colorization Tools: Create user-friendly interfaces and interactive tools that allow users to guide the colorization process manually. This could involve incorporating user inputs, such as color hints or strokes, to influence the final colorization output and provide more control over the results.Real-time Colorization Applications: Optimize colorization models for real-time applications, such as video colorization or live streaming. This involves reducing model complexity, optimizing inference speed, and leveraging hardware acceleration techniques to enable seamless integration into real-world systems.References:1. D.Futschik, “Colorization of black-and-white images using deep neural networks”. Jan,2018.2. V.Trivedi, H.Saifuddin, S.Gudadinni, \"Automatic Colorization of Black and White Images Based on CNN\", Sinhgad Academy of Engineering, Pune, India. May.5,2020.3. J.Hwang and Y.Zhou, “Image Colorization with Deep Convolutional Neural Networks”.2016.4. K.Kiani, R.Hemmatpour, and R.Rastgoo, “Automatic Grayscale Image Colorization using a Deep Hybrid Model”. May.13,2021.5. S.Kotala, S.Tirumalasetti, “Automatic Colorization of Black and White Images using Deep Learning”, Osmania University, Hyderabad, Telangana. April,2019.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(document.paragraphs)):\n",
        "  print(\"The content of the paragraph\"+str(i)+\" is: \" +document.paragraphs[i].text+\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9__ltWQLB5k",
        "outputId": "3f142f4b-79ca-44c7-9dda-c49102bf3967"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content of the paragraph0 is: Black and White Image Colorization with Deep Learning\n",
            "\n",
            "The content of the paragraph1 is: A project report submitted in partial fulfillment of the requirements for the award of the degree of\n",
            "\n",
            "The content of the paragraph2 is: Bachelor of Technology\n",
            "\n",
            "The content of the paragraph3 is: \n",
            "\n",
            "The content of the paragraph4 is: by\n",
            "\n",
            "The content of the paragraph5 is: \n",
            "\n",
            "The content of the paragraph6 is: \n",
            "\n",
            "The content of the paragraph7 is: \n",
            "\n",
            "The content of the paragraph8 is: Under the guidance of\n",
            "\n",
            "The content of the paragraph9 is: T.Ramya\n",
            "\n",
            "The content of the paragraph10 is: Assistant Professor\n",
            "\n",
            "The content of the paragraph11 is: \n",
            "\n",
            "The content of the paragraph12 is: DEPARTMENT OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING\n",
            "\n",
            "The content of the paragraph13 is: MALLA REDDY UNIVERSITY\n",
            "\n",
            "The content of the paragraph14 is: (As per Telangana State Private Universities Act No.13 of 2020 and G.O.Ms.No.14, Higher Education (UE) Department) HYDERABAD – 500043\n",
            "\n",
            "The content of the paragraph15 is: TELANAGANA INDIA2023-24\n",
            "\n",
            "The content of the paragraph16 is: \n",
            "\n",
            "The content of the paragraph17 is: MALLA REDDY UNIVERSITY\n",
            "\n",
            "The content of the paragraph18 is: (As per Telangana State Private Universities Act No.13 of 2020 and G.O.Ms.No.14, Higher Education (UE) Department) HYDERABAD – 500043\n",
            "\n",
            "The content of the paragraph19 is: TELANAGANA\n",
            "\n",
            "The content of the paragraph20 is: \n",
            "\n",
            "The content of the paragraph21 is: \n",
            "\n",
            "The content of the paragraph22 is: Certificate\n",
            "\n",
            "The content of the paragraph23 is: \n",
            "\n",
            "The content of the paragraph24 is: This is to certify that this is the bonafide record of the application development entitled, “Black and White Image Colorization with Deep Learning” submitted by L.Akhil (2111CS020028), B. Tech III year II semester, Department of CSE (AI &ML) during the year 2023-2024. The results embodied in the report have not been submitted to any other university or institute for the award of any degree or diploma.\n",
            "\n",
            "The content of the paragraph25 is: \n",
            "\n",
            "The content of the paragraph26 is: \n",
            "\n",
            "The content of the paragraph27 is: \n",
            "\n",
            "The content of the paragraph28 is: \n",
            "\n",
            "The content of the paragraph29 is: \n",
            "\n",
            "The content of the paragraph30 is: \n",
            "\n",
            "The content of the paragraph31 is: \n",
            "\n",
            "The content of the paragraph32 is: \n",
            "\n",
            "The content of the paragraph33 is: \n",
            "\n",
            "The content of the paragraph34 is: External Examiner \n",
            "\n",
            "The content of the paragraph35 is: \n",
            "\n",
            "The content of the paragraph36 is: \n",
            "\n",
            "The content of the paragraph37 is: ACKNOWLEDGEMENT\n",
            "\n",
            "The content of the paragraph38 is:      An endeavor over a long period can be successful with the advice and support of many well-wishers. We take this opportunity to express our gratitude and appreciation to all of them. We first take the privilege to thank Dr.Thayyaba Khatoon, Head of the Department, Computer Science & Engineering(AI&ML), for her valuable support and guidance during the period of project implementation. We wish to express our sincere thanks and gratitude to our project guide\n",
            "\n",
            "The content of the paragraph39 is: Prof. T.Ramya, Professor, Department of Computer Science and Engineering(AI&ML) for the simulating discussions, in analyzing problems associated with our project work and for guiding us throughout the project. Project meetings were highly informative. We express our warm and sincere thanks for the encouragement, untiring guidance and the confidence she had shown in us. We are immensely indebted for her valuable guidance throughout our project. We also thank all the staff members of AIML department for their valuable advices. We also thank supporting staff for providing resources as and when required.\n",
            "\n",
            "The content of the paragraph40 is: \n",
            "\n",
            "The content of the paragraph41 is: \n",
            "\n",
            "The content of the paragraph42 is: \n",
            "\n",
            "The content of the paragraph43 is: \n",
            "\n",
            "The content of the paragraph44 is: \n",
            "\n",
            "The content of the paragraph45 is: \n",
            "\n",
            "The content of the paragraph46 is: \n",
            "\n",
            "The content of the paragraph47 is: \n",
            "\n",
            "The content of the paragraph48 is: \n",
            "\n",
            "The content of the paragraph49 is: \n",
            "\n",
            "The content of the paragraph50 is: \n",
            "\n",
            "The content of the paragraph51 is: \n",
            "\n",
            "The content of the paragraph52 is: \n",
            "\n",
            "The content of the paragraph53 is: \n",
            "\n",
            "The content of the paragraph54 is: \n",
            "\n",
            "The content of the paragraph55 is: \n",
            "\n",
            "The content of the paragraph56 is: \n",
            "\n",
            "The content of the paragraph57 is: \n",
            "\n",
            "The content of the paragraph58 is: \n",
            "\n",
            "The content of the paragraph59 is: \n",
            "\n",
            "The content of the paragraph60 is: \n",
            "\n",
            "The content of the paragraph61 is: \n",
            "\n",
            "The content of the paragraph62 is: \n",
            "\n",
            "The content of the paragraph63 is: \n",
            "\n",
            "The content of the paragraph64 is: \n",
            "\n",
            "The content of the paragraph65 is: ABSTRACT\n",
            "\n",
            "The content of the paragraph66 is: \n",
            "\n",
            "The content of the paragraph67 is:      The project, \" Black and White Image Colorization with Deep Learning,\" focuses on developing an innovative solution to automatically add realistic and aesthetically pleasing colors to grayscale images. Employing state-of-the-art deep learning techniques, including convolutional neural networks (CNNs) and generative models, our approach aims to capture intricate details and nuances in the colorization process. The abstracted methodology involves extensive training on diverse image datasets, fine-tuning model parameters, and exploring advanced loss functions to achieve high-fidelity color representations. The project not only addresses the technical challenges of accurate colorization but also aims to enhance user interactivity by providing customizable features such as style transfer and color grading. By combining the power of deep learning and computer vision, this project contributes to the broader field of image processing, offering a versatile tool for both historical photo restoration and creative content generation. Through experimentation and optimization, we aim to achieve a robust and user-friendly system that pushes the boundaries of image colorization in the digital era.\n",
            "\n",
            "The content of the paragraph68 is: \n",
            "\n",
            "The content of the paragraph69 is: \n",
            "\n",
            "The content of the paragraph70 is:                        CONTENTS\n",
            "\n",
            "The content of the paragraph71 is: \n",
            "\n",
            "The content of the paragraph72 is: \n",
            "\n",
            "The content of the paragraph73 is: \n",
            "\n",
            "The content of the paragraph74 is: 1.INTRODUCTION\n",
            "\n",
            "The content of the paragraph75 is: \n",
            "\n",
            "The content of the paragraph76 is: Problem definition:\n",
            "\n",
            "The content of the paragraph77 is: \n",
            "\n",
            "The content of the paragraph78 is: Colorization of black and white images is a longstanding challenge in computer vision, requiring the development of advanced algorithms to automatically add realistic colors to grayscale images. While manual colorization methods exist, they are time-consuming and labor-intensive. Additionally, existing automated solutions often lack accuracy and fail to capture intricate details accurately. Therefore, the project aims to leverage deep learning techniques to develop a robust and efficient system for black and white image colorization. This system should accurately infer color information from grayscale inputs, producing visually appealing and contextually appropriate colorized images. Key objectives include achieving high-quality colorization results across diverse image genres and optimizing computational efficiency to enable real-time or near-real-time performance on standard hardware configurations.\n",
            "\n",
            "The content of the paragraph79 is: \n",
            "\n",
            "The content of the paragraph80 is: Objective of project:\n",
            "\n",
            "The content of the paragraph81 is: \n",
            "\n",
            "The content of the paragraph82 is: The primary objectives include training the model on diverse datasets to ensure robust performance across various image styles, enhancing colorization accuracy through advanced feature extraction and context-aware mapping, and validating results using qualitative and quantitative evaluation metrics. \n",
            "\n",
            "The content of the paragraph83 is: Additionally, the project aims to provide a user-friendly interface for easy deployment and utilization, while also exploring avenues for further refinement and optimization, including real-time performance. \n",
            "\n",
            "The content of the paragraph84 is: Ultimately, the project seeks to contribute to advancements in computer vision and image processing fields by providing a reliable and scalable solution for automating the colorization process, with potential applications in digital restoration, historical preservation, and multimedia content creation.\n",
            "\n",
            "The content of the paragraph85 is: \n",
            "\n",
            "The content of the paragraph86 is: \n",
            "\n",
            "The content of the paragraph87 is: \n",
            "\n",
            "The content of the paragraph88 is: \n",
            "\n",
            "The content of the paragraph89 is: \n",
            "\n",
            "The content of the paragraph90 is: \n",
            "\n",
            "The content of the paragraph91 is: \n",
            "\n",
            "The content of the paragraph92 is: Scope & Limitations:\n",
            "\n",
            "The content of the paragraph93 is: Scope:\n",
            "\n",
            "The content of the paragraph94 is: Data Dependency: The effectiveness of deep learning models heavily relies on the availability and quality of training data. Limited or biased datasets may lead to suboptimal performance and generalization issues.\n",
            "\n",
            "The content of the paragraph95 is: Computational Resources: Training deep neural networks for image colorization requires significant computational resources, including high-performance GPUs and substantial memory capacity. This can pose challenges for individuals or organizations with limited access to such resources.\n",
            "\n",
            "The content of the paragraph96 is: Domain Specificity: Models trained on specific datasets may struggle to generalize to images from different domains or time periods. Adapting the model to diverse styles and contexts could require additional training or fine-tuning on relevant data\n",
            "\n",
            "The content of the paragraph97 is: \n",
            "\n",
            "The content of the paragraph98 is: \n",
            "\n",
            "The content of the paragraph99 is: Limitations:\n",
            "\n",
            "The content of the paragraph100 is: \n",
            "\n",
            "The content of the paragraph101 is: Artifact Generation: Deep learning models may produce artifacts or unrealistic colorizations, especially in regions with complex textures or ambiguous features. Mitigating such artifacts typically requires post-processing techniques or refinement strategies.\n",
            "\n",
            "The content of the paragraph102 is: Ethical Considerations: Colorization algorithms may inadvertently perpetuate biases present in training data, leading to unintended consequences such as reinforcing stereotypes or cultural misrepresentations. Careful consideration of ethical implications is essential throughout the development and deployment of such technologies.\n",
            "\n",
            "The content of the paragraph103 is: \n",
            "\n",
            "The content of the paragraph104 is: Literature Survey:\n",
            "\n",
            "The content of the paragraph105 is: The literature surrounding black and white image colorization encompasses a diverse range of methodologies, techniques, and applications. Early approaches often relied on handcrafted rules or segmentation-based algorithms to assign colors to grayscale regions.Several studies have explored various architectures, loss functions, and training strategies to improve colorization quality and efficiency. \n",
            "\n",
            "The content of the paragraph106 is: For instance, Zhang et al. (2016) introduced a deep learning-based approach using a CNN to directly predict chrominance values from grayscale inputs, achieving impressive results.\n",
            "\n",
            "The content of the paragraph107 is: Similarly, Iizuka et al. (2016) proposed a deep learning framework incorporating a global and local colorization network to enhance colorization performance. \n",
            "\n",
            "The content of the paragraph108 is: Furthermore, advancements in generative adversarial networks (GANs) have led to novel techniques for realistic and high-resolution colorization, as demonstrated by Isola et al. (2017) with their pix2pix model. \n",
            "\n",
            "The content of the paragraph109 is: Beyond technical innovations, research in this area has also explored the cultural and historical implications of colorization, addressing issues such as authenticity, preservation of cultural heritage, and ethical considerations surrounding the manipulation of historical imagery.\n",
            "\n",
            "The content of the paragraph110 is: \n",
            "\n",
            "The content of the paragraph111 is: \n",
            "\n",
            "The content of the paragraph112 is: \n",
            "\n",
            "The content of the paragraph113 is: \n",
            "\n",
            "The content of the paragraph114 is: \n",
            "\n",
            "The content of the paragraph115 is: \n",
            "\n",
            "The content of the paragraph116 is: \n",
            "\n",
            "The content of the paragraph117 is: \n",
            "\n",
            "The content of the paragraph118 is: \n",
            "\n",
            "The content of the paragraph119 is: \n",
            "\n",
            "The content of the paragraph120 is: \n",
            "\n",
            "The content of the paragraph121 is: \n",
            "\n",
            "The content of the paragraph122 is: \n",
            "\n",
            "The content of the paragraph123 is: \n",
            "\n",
            "The content of the paragraph124 is: \n",
            "\n",
            "The content of the paragraph125 is: \n",
            "\n",
            "The content of the paragraph126 is: \n",
            "\n",
            "The content of the paragraph127 is: 2. ANALYSIS\n",
            "\n",
            "The content of the paragraph128 is: \n",
            "\n",
            "The content of the paragraph129 is: Project Planning and Research:\n",
            "\n",
            "The content of the paragraph130 is: \n",
            "\n",
            "The content of the paragraph131 is: Define project objectives: Establish the primary goal of developing a black and white image colorization model using deep learning.\n",
            "\n",
            "The content of the paragraph132 is: Resource allocation: Allocate personnel, computational resources, and budget for data acquisition, model development, and testing.\n",
            "\n",
            "The content of the paragraph133 is: Task prioritization: Prioritize tasks based on dependencies and project objectives to ensure efficient progress.\n",
            "\n",
            "The content of the paragraph134 is: Identify techniques and architectures: Explore popular techniques, architectures, datasets, and evaluation metrics used in previous studies.\n",
            "\n",
            "The content of the paragraph135 is: Model selection: Evaluate different deep learning architectures such as CNNs, GANs, and autoencoders for image colorization, considering factors like model complexity and performance on similar tasks.\n",
            "\n",
            "The content of the paragraph136 is: \n",
            "\n",
            "The content of the paragraph137 is: 2.2 Software requirement specification: \n",
            "\n",
            "The content of the paragraph138 is: 2.2.1 Software requirement: \n",
            "\n",
            "The content of the paragraph139 is: 1.google colab or jupyter notebook: Notebook is an interact computing environment that allows you to create and share documents containing live code equations, visualizations, and narrative text. it’s commonly used for prototyping and experimenting with deep learning models. \n",
            "\n",
            "The content of the paragraph140 is: 2. Python Compiler with all the required modules available: All the Code written to execute the solution is written in the python code where any basic system with compiler and required specifications fulfilled can run the code. \n",
            "\n",
            "The content of the paragraph141 is: 3.Integrated Development Environment (IDE): IDEs like Visual studio code provide features like code editing, debugging, and project management making them essential for deep learning development workflows.\n",
            "\n",
            "The content of the paragraph142 is: 2.2.2 Hardware requirement: \n",
            "\n",
            "The content of the paragraph143 is: 1.Memory (RAM): Sufficient RAM is essential for loading large datasets into memory, especially during data preprocessing and model training. Deep learning models with large parameter counts also require significant memory during training. \n",
            "\n",
            "The content of the paragraph144 is: 2.Central Processing unit (CPU) and Graphical Processing unit (GPU): Modern multi-core CPUs are essential for general-purpose computing tasks in deep learning, such as data processing, model evaluation.\n",
            "\n",
            "The content of the paragraph145 is: GPUs are the most widely used for deep learning due to their excellent support for CNNs and deep learning frameworks like TensorFlow and PyTorch. \n",
            "\n",
            "The content of the paragraph146 is: 3. NVIDIA GPU: Deep learning models benefit significantly from GPU acceleration. An NVIDIA GPU with CUDA support is recommended for faster training. \n",
            "\n",
            "The content of the paragraph147 is: For basic experimentation: NVIDIA GeForce GTX 1060 or higher.\n",
            "\n",
            "The content of the paragraph148 is: For larger models and datasets: NVIDIA GeForce RTX 2070 or higher, or NVIDIA Quadro series.\n",
            "\n",
            "The content of the paragraph149 is: \n",
            "\n",
            "The content of the paragraph150 is: Model Selection and Architecture: \n",
            "\n",
            "The content of the paragraph151 is: Model: \n",
            "\n",
            "The content of the paragraph152 is: Convolutional Neural Networks (CNNs):\n",
            "\n",
            "The content of the paragraph153 is: CNNs are widely used for various image-related tasks due to their ability to automatically learn hierarchical representations of input images. In the context of image colorization, CNNs can be trained to map grayscale images to corresponding color images.\n",
            "\n",
            "The content of the paragraph154 is: Effective at capturing local and global spatial dependencies in images.\n",
            "\n",
            "The content of the paragraph155 is: Can be trained end-to-end for image colorization tasks.\n",
            "\n",
            "The content of the paragraph156 is: \n",
            "\n",
            "The content of the paragraph157 is: \n",
            "\n",
            "The content of the paragraph158 is: \n",
            "\n",
            "The content of the paragraph159 is: \n",
            "\n",
            "The content of the paragraph160 is: \n",
            "\n",
            "The content of the paragraph161 is: \n",
            "\n",
            "The content of the paragraph162 is: \n",
            "\n",
            "The content of the paragraph163 is: \n",
            "\n",
            "The content of the paragraph164 is: \n",
            "\n",
            "The content of the paragraph165 is: \n",
            "\n",
            "The content of the paragraph166 is: \n",
            "\n",
            "The content of the paragraph167 is: \n",
            "\n",
            "The content of the paragraph168 is: Architecture: \n",
            "\n",
            "The content of the paragraph169 is: \n",
            "\n",
            "The content of the paragraph170 is: \n",
            "\n",
            "The content of the paragraph171 is: \n",
            "\n",
            "The content of the paragraph172 is: Fig.2.3.1\n",
            "\n",
            "The content of the paragraph173 is: 3.DESIGN\n",
            "\n",
            "The content of the paragraph174 is: \n",
            "\n",
            "The content of the paragraph175 is: 3.1 Introduction: \n",
            "\n",
            "The content of the paragraph176 is: \n",
            "\n",
            "The content of the paragraph177 is:      The E-R diagram for a plant disease prediction system would typically include image analyzer image enhancement, image segmentation, feature extraction, classifier and detection. \n",
            "\n",
            "The content of the paragraph178 is: The datasets contain the images classified according to their plant health in different folders and these folders are used accordingly to train the CNN. \n",
            "\n",
            "The content of the paragraph179 is: \n",
            "\n",
            "The content of the paragraph180 is: 3.2 ER Diagram:\n",
            "\n",
            "The content of the paragraph181 is: \n",
            "\n",
            "The content of the paragraph182 is: Fig.3.2.1\n",
            "\n",
            "The content of the paragraph183 is: \n",
            "\n",
            "The content of the paragraph184 is: 3.3 Dataset Descriptions:\n",
            "\n",
            "The content of the paragraph185 is: \n",
            "\n",
            "The content of the paragraph186 is:     For an image colorization project using deep learning, you would typically need two types of datasets: grayscale images and their corresponding colorized versions.\n",
            "\n",
            "The content of the paragraph187 is: \n",
            "\n",
            "The content of the paragraph188 is: Grayscale Images:\n",
            "Grayscale images serve as the input to the colorization model. These images lack color information and are typically represented in shades of gray.\n",
            "Format: JPEG, PNG, or any other common image format.\n",
            "Size: Variable, depending on the source and application.\n",
            "\n",
            "The content of the paragraph189 is: \n",
            "\n",
            "The content of the paragraph190 is: Sample images:\n",
            "\n",
            "The content of the paragraph191 is: 3.4 Data Preprocessing Techniques: \n",
            "\n",
            "The content of the paragraph192 is: Image Resizing : Resize images to a consistent resolution to ensure uniformity across the dataset. This step helps reduce computational overhead during training and ensures compatibility with the model's input size requirements..\n",
            "\n",
            "The content of the paragraph193 is: Normalization : Normalize pixel values to a common scale, typically between 0 and 1 or -1 and 1. Normalization helps stabilize training by ensuring that input values are within a similar range, which can improve convergence and model performance.\n",
            "\n",
            "The content of the paragraph194 is: \n",
            "\n",
            "The content of the paragraph195 is: 3.5 Methods & Algorithms:\n",
            "\n",
            "The content of the paragraph196 is: Methods: \n",
            "\n",
            "The content of the paragraph197 is:      The methods involve the several steps of projects such as data collection, data pre processing choosing the model to train and train and test split of the model where finally the algorithms will be integrated to help with the predictions.\n",
            "\n",
            "The content of the paragraph198 is: Algorithms:\n",
            "\n",
            "The content of the paragraph199 is: Convolutional Neural Networks (CNNs)\n",
            "\n",
            "The content of the paragraph200 is: Encoder-Decoder Architecture : Utilized for learning high-level feature representations from input grayscale images and generating corresponding colorized outputs.\n",
            "\n",
            "The content of the paragraph201 is: Activation Functions : Typically ReLU (Rectified Linear Unit) activation functions are used in intermediate layers to introduce non-linearity.\n",
            "\n",
            "The content of the paragraph202 is: Normalization Layers : Batch normalization or instance normalization layers are often applied to stabilize and accelerate the training process.\n",
            "\n",
            "The content of the paragraph203 is: \n",
            "\n",
            "The content of the paragraph204 is: Preprocessing Techniques:\n",
            "\n",
            "The content of the paragraph205 is: Normalization : Normalizing input grayscale images to a standard range (e.g., [0, 1]) before feeding them into the network.\n",
            "\n",
            "The content of the paragraph206 is: DEPLOYMENT AND RESULTS\n",
            "\n",
            "The content of the paragraph207 is: \n",
            "\n",
            "The content of the paragraph208 is: 4.1 Introduction:\n",
            "\n",
            "The content of the paragraph209 is: \n",
            "\n",
            "The content of the paragraph210 is:      To implement the project, the code was written in Python using libraries such as NumPy, OpenCV (cv2), and TensorFlow. The dataset preprocessing involved resizing images and converting them to suitable formats using NumPy arrays. The core of the implementation relied on Convolutional Neural Network (CNN) training, testing, and validation procedures to achieve image colorization.\n",
            "\n",
            "The content of the paragraph211 is:  \n",
            "\n",
            "The content of the paragraph212 is:  4.2 Source Code:\n",
            "\n",
            "The content of the paragraph213 is: \n",
            "\n",
            "The content of the paragraph214 is: import numpy as np\n",
            "\n",
            "The content of the paragraph215 is: import argparse\n",
            "\n",
            "The content of the paragraph216 is: import cv2\n",
            "\n",
            "The content of the paragraph217 is: import os\n",
            "\n",
            "The content of the paragraph218 is: \n",
            "\n",
            "The content of the paragraph219 is: DIR = os.path.dirname(os.path.realpath(__file__))\n",
            "\n",
            "The content of the paragraph220 is: MODEL_DIR = os.path.join(DIR, \"model\") \n",
            "\n",
            "The content of the paragraph221 is: PROTOTXT = os.path.join(MODEL_DIR, \"colorization_deploy_v2.prototxt\")\n",
            "\n",
            "The content of the paragraph222 is: POINTS = os.path.join(MODEL_DIR, \"pts_in_hull.npy\")\n",
            "\n",
            "The content of the paragraph223 is: MODEL = os.path.join(MODEL_DIR, \"colorization_release_v2.caffemodel\")\n",
            "\n",
            "The content of the paragraph224 is: ap = argparse.ArgumentParser()\n",
            "\n",
            "The content of the paragraph225 is: ap.add_argument(\"-i\", \"--image\", type=str, required=True,\n",
            "\n",
            "The content of the paragraph226 is:                 help=\"path to input black and white image\")\n",
            "\n",
            "The content of the paragraph227 is: args = vars(ap.parse_args())\n",
            "\n",
            "The content of the paragraph228 is: print(\"Loading model...\")\n",
            "\n",
            "The content of the paragraph229 is: net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
            "\n",
            "The content of the paragraph230 is: pts = np.load(POINTS)\n",
            "\n",
            "The content of the paragraph231 is: class8 = net.getLayerId(\"class8_ab\")\n",
            "\n",
            "The content of the paragraph232 is: conv8 = net.getLayerId(\"conv8_313_rh\")\n",
            "\n",
            "The content of the paragraph233 is: pts = pts.transpose().reshape(2, 313, 1, 1)\n",
            "\n",
            "The content of the paragraph234 is: net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
            "\n",
            "The content of the paragraph235 is: net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n",
            "\n",
            "The content of the paragraph236 is: image = cv2.imread(args[\"image\"])\n",
            "\n",
            "The content of the paragraph237 is: scaled = image.astype(\"float32\") / 255.0\n",
            "\n",
            "The content of the paragraph238 is: lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
            "\n",
            "The content of the paragraph239 is: resized = cv2.resize(lab, (224, 224))\n",
            "\n",
            "The content of the paragraph240 is: L = cv2.split(resized)[0]\n",
            "\n",
            "The content of the paragraph241 is: L -= 50\n",
            "\n",
            "The content of the paragraph242 is: print(\"Colorizing the image...\")\n",
            "\n",
            "The content of the paragraph243 is: net.setInput(cv2.dnn.blobFromImage(L))\n",
            "\n",
            "The content of the paragraph244 is: ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
            "\n",
            "The content of the paragraph245 is: ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n",
            "\n",
            "The content of the paragraph246 is: L = cv2.split(lab)[0]\n",
            "\n",
            "The content of the paragraph247 is: colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
            "\n",
            "The content of the paragraph248 is: colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
            "\n",
            "The content of the paragraph249 is: colorized = np.clip(colorized, 0, 1)\n",
            "\n",
            "The content of the paragraph250 is: colorized = (255 * colorized).astype(\"uint8\")\n",
            "\n",
            "The content of the paragraph251 is: cv2.imshow(\"Original\", image)\n",
            "\n",
            "The content of the paragraph252 is: cv2.imshow(\"Colorized\", colorized)\n",
            "\n",
            "The content of the paragraph253 is: cv2.waitKey(0)\n",
            "\n",
            "The content of the paragraph254 is: \n",
            "\n",
            "The content of the paragraph255 is: 4.3 Model implementation and training:\n",
            "\n",
            "The content of the paragraph256 is: \n",
            "\n",
            "The content of the paragraph257 is: \n",
            "\n",
            "The content of the paragraph258 is: 4.4 Model evaluation metrics:\n",
            "\n",
            "The content of the paragraph259 is: import cv2\n",
            "\n",
            "The content of the paragraph260 is: import numpy as np\n",
            "\n",
            "The content of the paragraph261 is: from skimage.metrics import structural_similarity as ssim\n",
            "\n",
            "The content of the paragraph262 is: \n",
            "\n",
            "The content of the paragraph263 is: # Function to calculate PSNR\n",
            "\n",
            "The content of the paragraph264 is: def psnr(image1, image2):\n",
            "\n",
            "The content of the paragraph265 is:     mse = np.mean((image1 - image2) ** 2)\n",
            "\n",
            "The content of the paragraph266 is:     if mse == 0:\n",
            "\n",
            "The content of the paragraph267 is:         return float('inf')\n",
            "\n",
            "The content of the paragraph268 is:     max_pixel = 255.0\n",
            "\n",
            "The content of the paragraph269 is:     psnr_value = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
            "\n",
            "The content of the paragraph270 is:     return psnr_value\n",
            "\n",
            "The content of the paragraph271 is: \n",
            "\n",
            "The content of the paragraph272 is: # Load the ground truth colorized image and the predicted colorized image\n",
            "\n",
            "The content of the paragraph273 is: ground_truth_color_image = cv2.imread('ground_truth_color_image.jpg')\n",
            "\n",
            "The content of the paragraph274 is: predicted_color_image = cv2.imread('predicted_color_image.jpg')\n",
            "\n",
            "The content of the paragraph275 is: \n",
            "\n",
            "The content of the paragraph276 is: # Convert images to grayscale\n",
            "\n",
            "The content of the paragraph277 is: ground_truth_color_image_gray = cv2.cvtColor(ground_truth_color_image, cv2.COLOR_BGR2GRAY)\n",
            "\n",
            "The content of the paragraph278 is: predicted_color_image_gray = cv2.cvtColor(predicted_color_image, cv2.COLOR_BGR2GRAY)\n",
            "\n",
            "The content of the paragraph279 is: \n",
            "\n",
            "The content of the paragraph280 is: # Calculate MSE\n",
            "\n",
            "The content of the paragraph281 is: mse = np.mean((ground_truth_color_image_gray - predicted_color_image_gray) ** 2)\n",
            "\n",
            "The content of the paragraph282 is: \n",
            "\n",
            "The content of the paragraph283 is: # Calculate PSNR\n",
            "\n",
            "The content of the paragraph284 is: psnr_value = psnr(ground_truth_color_image_gray, predicted_color_image_gray)\n",
            "\n",
            "The content of the paragraph285 is: \n",
            "\n",
            "The content of the paragraph286 is: # Calculate SSIM\n",
            "\n",
            "The content of the paragraph287 is: ssim_index = ssim(ground_truth_color_image_gray, predicted_color_image_gray)\n",
            "\n",
            "The content of the paragraph288 is: \n",
            "\n",
            "The content of the paragraph289 is: print(\"Mean Squared Error (MSE):\", mse)\n",
            "\n",
            "The content of the paragraph290 is: print(\"Peak Signal-to-Noise Ratio (PSNR):\", psnr_value)\n",
            "\n",
            "The content of the paragraph291 is: print(\"Structural Similarity Index (SSIM):\", ssim_index)\n",
            "\n",
            "The content of the paragraph292 is: \n",
            "\n",
            "The content of the paragraph293 is: \n",
            "\n",
            "The content of the paragraph294 is:  \n",
            "\n",
            "The content of the paragraph295 is: \n",
            "\n",
            "The content of the paragraph296 is: 4.5 Model Deployment : Testing and Validation\n",
            "\n",
            "The content of the paragraph297 is: \n",
            "\n",
            "The content of the paragraph298 is: import cv2\n",
            "\n",
            "The content of the paragraph299 is: import numpy as np\n",
            "\n",
            "The content of the paragraph300 is: from skimage.metrics import mean_squared_error\n",
            "\n",
            "The content of the paragraph301 is: \n",
            "\n",
            "The content of the paragraph302 is: # Function to calculate Mean Squared Error (MSE) between two images\n",
            "\n",
            "The content of the paragraph303 is: def calculate_mse(image1, image2):\n",
            "\n",
            "The content of the paragraph304 is:     return mean_squared_error(image1, image2)\n",
            "\n",
            "The content of the paragraph305 is: \n",
            "\n",
            "The content of the paragraph306 is: # Load black and white image and its corresponding ground truth colored image\n",
            "\n",
            "The content of the paragraph307 is: bw_image = cv2.imread('black_white_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
            "\n",
            "The content of the paragraph308 is: ground_truth_colored_image = cv2.imread('ground_truth_colored_image.jpg')\n",
            "\n",
            "The content of the paragraph309 is: \n",
            "\n",
            "The content of the paragraph310 is: \n",
            "\n",
            "The content of the paragraph311 is: 4.6 Web GUI’s Development:\n",
            "\n",
            "The content of the paragraph312 is: \n",
            "\n",
            "The content of the paragraph313 is: \n",
            "\n",
            "The content of the paragraph314 is: import tkinter as tk\n",
            "\n",
            "The content of the paragraph315 is: from tkinter import filedialog\n",
            "\n",
            "The content of the paragraph316 is: from PIL import Image, ImageTk\n",
            "\n",
            "The content of the paragraph317 is: import numpy as np\n",
            "\n",
            "The content of the paragraph318 is: import cv2\n",
            "\n",
            "The content of the paragraph319 is: import os\n",
            "\n",
            "The content of the paragraph320 is: def colorize_image(image_path):\n",
            "\n",
            "The content of the paragraph321 is:     # Load the model\n",
            "\n",
            "The content of the paragraph322 is:     net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
            "\n",
            "The content of the paragraph323 is:     pts = np.load(POINTS)\n",
            "\n",
            "The content of the paragraph324 is:     class8 = net.getLayerId(\"class8_ab\")\n",
            "\n",
            "The content of the paragraph325 is:     conv8 = net.getLayerId(\"conv8_313_rh\")\n",
            "\n",
            "The content of the paragraph326 is:     pts = pts.transpose().reshape(2, 313, 1, 1)\n",
            "\n",
            "The content of the paragraph327 is:     net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
            "\n",
            "The content of the paragraph328 is:     net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n",
            "\n",
            "The content of the paragraph329 is:     image = cv2.imread(image_path)\n",
            "\n",
            "The content of the paragraph330 is:     scaled = image.astype(\"float32\") / 255.0\n",
            "\n",
            "The content of the paragraph331 is:     lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
            "\n",
            "The content of the paragraph332 is:     resized = cv2.resize(lab, (224, 224))\n",
            "\n",
            "The content of the paragraph333 is:     L = cv2.split(resized)[0]\n",
            "\n",
            "The content of the paragraph334 is:     L -= 50\n",
            "\n",
            "The content of the paragraph335 is:     net.setInput(cv2.dnn.blobFromImage(L))\n",
            "\n",
            "The content of the paragraph336 is:     ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
            "\n",
            "The content of the paragraph337 is:     ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n",
            "\n",
            "The content of the paragraph338 is:     L = cv2.split(lab)[0]\n",
            "\n",
            "The content of the paragraph339 is:     colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
            "\n",
            "The content of the paragraph340 is:     colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
            "\n",
            "The content of the paragraph341 is:     colorized = np.clip(colorized, 0, 1)\n",
            "\n",
            "The content of the paragraph342 is:     colorized = (255 * colorized).astype(\"uint8\")\n",
            "\n",
            "The content of the paragraph343 is:     return colorized\n",
            "\n",
            "The content of the paragraph344 is: root = tk.Tk()\n",
            "\n",
            "The content of the paragraph345 is: root.title(\"Black and White Image \n",
            "\n",
            "The content of the paragraph346 is: original_label = tk.Label(root, text=\"Original Image\")\n",
            "\n",
            "The content of the paragraph347 is: original_label.grid(row=0, column=0, padx=10, pady=10)\n",
            "\n",
            "The content of the paragraph348 is: colorized_label = tk.Label(root, text=\"Colorized Image\")\n",
            "\n",
            "The content of the paragraph349 is: colorized_label.grid(row=0, column=1, padx=10, pady=10)\n",
            "\n",
            "The content of the paragraph350 is: def browse_and_colorize():\n",
            "\n",
            "The content of the paragraph351 is:     image_path = filedialog.askopenfilename()\n",
            "\n",
            "The content of the paragraph352 is:     colorized_image = colorize_image(image_path)\n",
            "\n",
            "The content of the paragraph353 is:     original_image = Image.open(image_path)\n",
            "\n",
            "The content of the paragraph354 is:     original_image.thumbnail((300, 300))\n",
            "\n",
            "The content of the paragraph355 is:     original_photo = ImageTk.PhotoImage(original_image)\n",
            "\n",
            "The content of the paragraph356 is:     original_label.config(image=original_photo)\n",
            "\n",
            "The content of the paragraph357 is:     original_label.image = original_photo\n",
            "\n",
            "The content of the paragraph358 is:     colorized_photo = ImageTk.PhotoImage(Image.fromarray(colorized_image))\n",
            "\n",
            "The content of the paragraph359 is:     colorized_label.config(image=colorized_photo)\n",
            "\n",
            "The content of the paragraph360 is:     colorized_label.image = colorized_photo\n",
            "\n",
            "The content of the paragraph361 is: colorize_button = tk.Button(root, text=\"Select and Colorize\", bg=\"#2ecc71\", fg=\"white\", relief=tk.FLAT, command=browse_and_colorize)\n",
            "\n",
            "The content of the paragraph362 is: colorize_button.grid(row=1, column=0, columnspan=2, padx=10, pady=10, sticky=\"we\")\n",
            "\n",
            "The content of the paragraph363 is: root.mainloop()\n",
            "\n",
            "The content of the paragraph364 is: \n",
            "\n",
            "The content of the paragraph365 is: \n",
            "\n",
            "The content of the paragraph366 is: Fig.4.6.1\n",
            "\n",
            "The content of the paragraph367 is:  4.7 Results:\n",
            "\n",
            "The content of the paragraph368 is: 1. select the black and white image to be colorized\n",
            "\n",
            "The content of the paragraph369 is: 2. click “Colorize”\n",
            "\n",
            "The content of the paragraph370 is: Fig.4.7.1\n",
            "\n",
            "The content of the paragraph371 is: 5.CONCLUSION\n",
            "\n",
            "The content of the paragraph372 is: 5.1 Project conclusion:\n",
            "\n",
            "The content of the paragraph373 is: In conclusion, the ability to colorize black and white images has significant applications in various fields, including photography restoration, historical image enhancement, and artistic expression. Through the utilization of deep learning models, particularly convolutional neural networks (CNNs), we've developed a colorization model capable of transforming grayscale images into vibrant, color-rich representations.\n",
            "\n",
            "However, the effectiveness of such models heavily relies on the quality and diversity of the training data. Additionally, continuous improvements in model architecture, optimization techniques, and dataset augmentation strategies are essential to enhance the colorization accuracy and generalization capabilities. While our colorization model demonstrates promising results, there is still room for refinement and optimization. Future work could focus on addressing challenges such as handling complex scenes, improving color consistency, and expanding the model's applicability to diverse image datasets.\n",
            "\n",
            "The content of the paragraph374 is: 5.2 Future Scope:\n",
            "\n",
            "The content of the paragraph375 is: Enhanced Model Architectures: Continuously refine and optimize deep learning architectures specifically designed for colorization tasks. This includes exploring novel network architectures, such as attention mechanisms, recurrent neural networks (RNNs), or transformer models, to improve colorization accuracy and efficiency.\n",
            "Fine-grained Colorization: Develop techniques to enable more precise and detailed colorization, especially in regions with intricate patterns or textures. This could involve integrating high-resolution image representations or leveraging advanced feature extraction methods.\n",
            "\n",
            "The content of the paragraph376 is: Interactive Colorization Tools: Create user-friendly interfaces and interactive tools that allow users to guide the colorization process manually. This could involve incorporating user inputs, such as color hints or strokes, to influence the final colorization output and provide more control over the results.\n",
            "\n",
            "The content of the paragraph377 is: Real-time Colorization Applications: Optimize colorization models for real-time applications, such as video colorization or live streaming. This involves reducing model complexity, optimizing inference speed, and leveraging hardware acceleration techniques to enable seamless integration into real-world systems.\n",
            "\n",
            "The content of the paragraph378 is: References:\n",
            "\n",
            "The content of the paragraph379 is: 1. D.Futschik, “Colorization of black-and-white images using deep neural networks”. Jan,2018.\n",
            "\n",
            "The content of the paragraph380 is: \n",
            "\n",
            "The content of the paragraph381 is: 2. V.Trivedi, H.Saifuddin, S.Gudadinni, \"Automatic Colorization of Black and White Images Based on CNN\", Sinhgad Academy of Engineering, Pune, India. May.5,2020.\n",
            "\n",
            "The content of the paragraph382 is: \n",
            "\n",
            "The content of the paragraph383 is: 3. J.Hwang and Y.Zhou, “Image Colorization with Deep Convolutional Neural Networks”.2016.\n",
            "\n",
            "The content of the paragraph384 is: \n",
            "\n",
            "The content of the paragraph385 is: 4. K.Kiani, R.Hemmatpour, and R.Rastgoo, “Automatic Grayscale Image Colorization using a Deep Hybrid Model”. May.13,2021.\n",
            "\n",
            "The content of the paragraph386 is: \n",
            "\n",
            "The content of the paragraph387 is: 5. S.Kotala, S.Tirumalasetti, “Automatic Colorization of Black and White Images using Deep Learning”, Osmania University, Hyderabad, Telangana. April,2019.\n",
            "\n",
            "The content of the paragraph388 is: \n",
            "\n",
            "The content of the paragraph389 is: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collecting text from HTML**"
      ],
      "metadata": {
        "id": "GR-xA0TBNLp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8vqtxlqNP2A",
        "outputId": "76f8d5e8-69a6-4b2f-ad53-e6b175194495"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.12.2)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as urllib2\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "aiLBQzWyNU6o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=urllib2.urlopen(\"https://en.wikipedia.org/wiki/Natural_language_processing\")\n",
        "html_doc=response.read()"
      ],
      "metadata": {
        "id": "di2WQJUDNfpQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup=BeautifulSoup(html_doc,\"html.parser\")\n",
        "strhtm=soup.prettify()\n",
        "print(strhtm[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIADsT2_NpyP",
        "outputId": "4f6e76b4-4ab6-41a4-a9b4-56732a3e5614"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <title>\n",
            "   Natural language processing - Wikipedia\n",
            "  </title>\n",
            "  <script>\n",
            "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\n",
            "\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"d79e7f30-9e29-49dd-932a-f1f00c0a809f\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1274942014,\"wgRevisionId\":1274942014,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"Harv and Sfn no-target errors\",\"CS1 errors: periodical ignored\",\"CS1 maint: location\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Articles needing additional references from May 2024\",\"All articles needing additional references\",\"All articles with unsourced statements\",\"Articles with unsourced statements from May 2024\",\"Commons category link from Wikidata\",\n",
            "\"Natural language processing\",\"Computational fields of study\",\"Computational linguistics\",\"Speech recognition\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Natural_language_processing\",\"wgRelevantArticleId\":21652,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":0,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\n",
            "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q30642\",\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.scribunto.logs\",\"site\",\n",
            "\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GFUXT_4N3wL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}